# switch from DHCP to a static IP address
# edit "/etc/network/intertfaces"
# replace "dhcp" with "static and# add the following lines:
      address 10.3.0.XXX  ## here use the correct IP address
      gateway 10.3.0.1
      netmask 255.255.255.0


# Fix the "/etc/hots" entry to enable correct binding and name lookup
# see http://ria101.wordpress.com/2010/01/28/setup-hbase-in-pseudo-distributed-mode-and-connect-java-client/

# get IP address from /etc/network/interfaces
grep address  /etc/network/interfaces

# replace "127.0.1.1" in "/etc/hosts" with this address
sudo pico /etc/hosts

# make sure that the second DNS server in "/etc/resolv.conf" is 10.3.0.3

# in "/etc/nsswicth.conf" alter the "host:" line
# "dns" should become the second entry
=========================================================

# install alternative for the configuration
sudo update-alternatives --install /etc/hadoop-0.20/conf hadoop-0.20-conf /home/hadoop/conf 90

# create hadoop specific directories (as user hadoop)
mkdir -p /home/hadoop/dfs/name
mkdir -p /home/hadoop/dfs/data
mkdir -p /hd1/hadoop/dfs/data
mkdir -p /hd2/hadoop/dfs/data
mkdir -p /home/hadoop/dfs/checkpoint
mkdir -p /home/hadoop/mapred/local
mkdir -p /hd1/hadoop/mapred/local
mkdir -p /hd2/hadoop/mapred/local
mkdir -p /home/hadoop/mapred/temp

# in one paste line
mkdir -p /home/hadoop/dfs/name && mkdir -p /home/hadoop/dfs/data && mkdir -p /hd1/hadoop/dfs/data && mkdir -p /hd2/hadoop/dfs/data && mkdir -p /home/hadoop/dfs/checkpoint && mkdir -p /home/hadoop/mapred/local && mkdir -p /hd1/hadoop/mapred/local && mkdir -p /hd2/hadoop/mapred/local && mkdir -p /home/hadoop/mapred/temp
