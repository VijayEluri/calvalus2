#####################################################################################################################
#
# File: config/calvalus.properties
#
# Read by com.bc.calvalus.portal.server.BackendConfig.
# Properties in this file may be overridden by Java System properties.
#
# A parameter of format "calvalus.hadoop.<name>" will become a Hadoop job configuration properties "<name>".
#
#####################################################################################################################

# Factory that instantiates the production service.
# calvalus.portal.productionServiceFactory.class=com.bc.calvalus.production.local.LocalProductionServiceFactory
calvalus.portal.productionServiceFactory.class = com.bc.calvalus.production.hadoop.HadoopProductionServiceFactory

# optional location for production DB and user regions
# default is ~/.calvalus
calvalus.portal.appDataDir = /home/cvop/.ccprocessing

# optional path of archive root, location of product-sets.csv
# absolute or relative to /calvalus , default eodata
calvalus.portal.archiveRootDir = /calvalus/projects/cc/archive

# optional path of software bundles dir
# default is /calvalus/software/1.0
calvalus.portal.softwareDir = /calvalus/projects/cc/software

# optional user role for this portal configuration
# default is not to provide this property
calvalus.portal.userRole = coastcolour

# Output file staging directory.
# Value is relative to the context's directory
calvalus.portal.staging.path =  staging

# File upload directory (not yet used).
# Value is relative to the context's directory
calvalus.portal.upload.path = uploads

 # Hadoop HDFS locator "fs.default.name"
#calvalus.hadoop.fs.defaultFS = hdfs://master00:9000
calvalus.hadoop.fs.defaultFS = hdfs://calvalus
calvalus.hadoop.dfs.nameservices = calvalus
calvalus.hadoop.dfs.ha.namenodes.calvalus = nn1,nn2
calvalus.hadoop.dfs.namenode.rpc-address.calvalus.nn1 = master00:8020
calvalus.hadoop.dfs.namenode.rpc-address.calvalus.nn2 = master01:8020
calvalus.hadoop.dfs.client.failover.proxy.provider.calvalus = org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

# Hadoop namenode locator "mapred.job.tracker"
#calvalus.hadoop.yarn.resourcemanager.address = master00:8032

# optional production queue to submit jobs to when using the portal
# default is default
calvalus.hadoop.mapreduce.job.queuename = cc

# Hadoop job priority, can be VERY_HIGH, HIGH, NORMAL, LOW, VERY_LOW
calvalus.hadoop.mapreduce.job.priority = HIGH

# accepted failure percentage
calvalus.hadoop.mapreduce.map.failures.maxpercent = 5

# Calvalus software bundle "calvalus.calvalus.bundle"
calvalus.hadoop.calvalus.calvalus.bundle = calvalus-2.7-SNAPSHOT

# BEAM software bundle "calvalus.beam.bundle"
calvalus.hadoop.calvalus.beam.bundle = beam-5.0.1

calvalus.hadoop.mapreduce.framework.name = yarn
#calvalus.hadoop.yarn.resourcemanager.hostname = master00
calvalus.hadoop.yarn.resourcemanager.ha.enabled = true
calvalus.hadoop.yarn.resourcemanager.cluster-id = calvalus-yarn
calvalus.hadoop.yarn.resourcemanager.ha.rm-ids = rm1,rm2
calvalus.hadoop.yarn.resourcemanager.hostname.rm1 = master00
calvalus.hadoop.yarn.resourcemanager.hostname.rm2 = master01
calvalus.hadoop.yarn.client.failover-proxy-provider = org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider

# for Windows developer debugging the portal this may be necessary
calvalus.hadoop.mapreduce.app-submission.cross-platform = true
